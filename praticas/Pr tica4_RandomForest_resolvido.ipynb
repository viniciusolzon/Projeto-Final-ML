{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prática4_RandomForest_resolvido.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPJyasvy44dBZRXu77cS9KL"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sKPfuEnapDnU"},"source":["# <font color=\"darkblue\"> Prática 04: Random Forest </font>"]},{"cell_type":"markdown","metadata":{"id":"nKa5whanpntS"},"source":["**Objetivos:**\n","\n","\n","*   Comparar os resultados da Árvore de Decisão induzida por dados com o algoritmo de *Random Forest*;\n","*   Implementar o *tunning* do algoritmo de *Random Forest*.  \n","\n","**Requisitos de execução:**\n","\n","\n","*   Upload do arquivo *diabetes.csv*"]},{"cell_type":"markdown","metadata":{"id":"OPCbV-Udr1Pz"},"source":["**Atividade 1:**\n","\n","1. Visitar a base de dados: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n","2. Carregar os dados do arquivo *diabetes.csv* utilizando o pandas.\n","\n","    "]},{"cell_type":"code","metadata":{"id":"ZROjmwlFocyd"},"source":["import pandas as pd \n","\n","diabete = pd.read_csv(\"diabetes.csv\", sep=',')\n","\n","# Pega o cabecalho do arquivo\n","print(diabete.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O73AMlZRtOTU"},"source":["**Atividade 2:**\n","\n","1. Extrair os valores do *DataFrame* pandas e dividir em dados de treino e teste.\n"]},{"cell_type":"code","metadata":{"id":"sU9ugDeOtaHd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636019847989,"user_tz":180,"elapsed":838,"user":{"displayName":"Gilberto Farias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08659255523274913012"}},"outputId":"5a8c7b93-994c-4664-e665-a70c1d9e92e0"},"source":["from sklearn.model_selection import train_test_split\n","\n","Features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',  'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n","X = diabete[Features].values\n","y = diabete.Outcome.values\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2698)\n","\n","print(\"Tamanho treino: \" + str(len(x_train)))\n","print(\"Tamanho teste: \" + str(len(x_test)))\n"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Tamanho treino: 614\n","Tamanho teste: 154\n"]}]},{"cell_type":"markdown","metadata":{"id":"gGjfXNZ-tsor"},"source":["**Atividade 3:**\n","\n","1. Utilize a classe *DecisionTreeClassifier*, importada do pacote *sklearn.tree*, para inferir aprendizado dos dados de treinamento;\n","2. Compute as métricas de aprendizado sobre os dados de teste."]},{"cell_type":"code","metadata":{"id":"jvw7C1Odt3Jb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636019854593,"user_tz":180,"elapsed":369,"user":{"displayName":"Gilberto Farias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08659255523274913012"}},"outputId":"a131c08a-0803-4736-b498-6038a5935b9d"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","clf = DecisionTreeClassifier()\n","clf.fit(x_train, y_train)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, clf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, clf.predict(x_test))))\n","print(classification_report(y_test, clf.predict(x_test)))"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Ein: 0.0000\n","Eout: 0.3442\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.72      0.73        98\n","           1       0.53      0.54      0.53        56\n","\n","    accuracy                           0.66       154\n","   macro avg       0.63      0.63      0.63       154\n","weighted avg       0.66      0.66      0.66       154\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"0SH_p2JeTmEN"},"source":["**Atividade 4:**\n","\n","\n","1. Utilize a classe *RandomForestClassifier*, importada do pacote *sklearn.ensemble*, para inferir aprendizado dos dados de treinamento;\n","2. Compute as métricas de aprendizado sobre os dados de teste e compare com os resultados da atividade anterior.\n","\n","Parâmetros:\n","\n","\n","*   *n_estimators* : número de árvore aleatórias inferidas\n","*   *max_depth* : profundidade máxima da árvore\n","\n"]},{"cell_type":"code","metadata":{"id":"GbnZN9PUQQ0d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636019871000,"user_tz":180,"elapsed":321,"user":{"displayName":"Gilberto Farias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08659255523274913012"}},"outputId":"e47b4700-40e4-463c-989e-7c69f4e67c3d"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Inicializa 100 arvores aleatórias\n","rf = RandomForestClassifier(n_estimators = 50, max_depth = 20, random_state = 42)\n","\n","rf.fit(x_train, y_train)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, rf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, rf.predict(x_test))))\n","print(classification_report(y_test, rf.predict(x_test)))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Ein: 0.0000\n","Eout: 0.2922\n","              precision    recall  f1-score   support\n","\n","           0       0.73      0.87      0.79        98\n","           1       0.65      0.43      0.52        56\n","\n","    accuracy                           0.71       154\n","   macro avg       0.69      0.65      0.65       154\n","weighted avg       0.70      0.71      0.69       154\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"7eMziL89QAyK"},"source":["**Atividade 5:**\n","\n","1. Implemente os valores dos hiperparâmetros que serão combinados durantea a fase de validação\n","\n","Parâmetros:\n","\n","*   *max_features* : número de características a serem consideradas em cada divisão da árvore\n","\n"]},{"cell_type":"code","metadata":{"id":"uZXxRdSyQBLX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636020256380,"user_tz":180,"elapsed":324,"user":{"displayName":"Gilberto Farias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08659255523274913012"}},"outputId":"6abaabd1-d329-49ae-8014-f4d62fe669e1"},"source":["import numpy as np\n","from pprint import pprint\n","\n","# Number of trees in random forest\n","n_estimators = [int(x) for x in np.linspace(start = 20, stop = 70, num = 6)]\n","# Number of features to consider at every split\n","max_features = ['sqrt', len(X[0])]\n","max_depth = [2, 5, 7, 10, 20, 30]\n","max_depth.append(None)\n","\n","# Create the random grid\n","param_grid = {'n_estimators': n_estimators,\n","               'max_features': max_features,\n","               'max_depth': max_depth,\n","              }\n","pprint(param_grid)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["{'max_depth': [2, 5, 7, 10, 20, 30, None],\n"," 'max_features': ['sqrt', 8],\n"," 'n_estimators': [20, 30, 40, 50, 60, 70]}\n"]}]},{"cell_type":"markdown","metadata":{"id":"voPhxvG5Yd19"},"source":["Atividade 6:\n","\n","1. Implementar a validação da Random Forest através da classe *GridSearchCV* do pacote *sklearn.model_selection*;\n","2. Imprimir os parâmetros do melhor classificador;\n","3. Imprimir os $E_{in}$ e $E_{out}$  e as métricas de aprendizado.\n","\n","Parâmetros:\n","\n","\n","*   *estimator* : instância do classificador cujos hiperparâmetros serão analisados;\n","*   *cv* : número de divisões do conjunto de treinamento para ser usado na técnica de validação cruzada (10 é um bom valor observado na prática);\n","*   *param_grid* : conjunto de parâmetros a serem combinados durante a fase de validação.\n","\n"]},{"cell_type":"code","metadata":{"id":"wj5q5XfBe80u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636020294751,"user_tz":180,"elapsed":34562,"user":{"displayName":"Gilberto Farias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08659255523274913012"}},"outputId":"44fa582e-42ed-426c-981f-e6e02c49b58c"},"source":["from sklearn.model_selection import GridSearchCV\n","\n","rf = RandomForestClassifier()\n","\n","CV_rf = GridSearchCV(estimator=rf, param_grid=param_grid, cv = 5, verbose=2, n_jobs=-1)\n","\n","# Fit the random search model\n","CV_rf.fit(x_train, y_train)\n","\n","print(CV_rf.best_estimator_)\n","\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, CV_rf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, CV_rf.predict(x_test))))\n","print(classification_report(y_test, CV_rf.predict(x_test)))\n","\n"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.8s\n","[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   24.7s\n","[Parallel(n_jobs=-1)]: Done 420 out of 420 | elapsed:   34.0s finished\n"]},{"output_type":"stream","name":"stdout","text":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=7, max_features=8,\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=70,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)\n","Ein: 0.0603\n","Eout: 0.2792\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.84      0.79        98\n","           1       0.64      0.52      0.57        56\n","\n","    accuracy                           0.72       154\n","   macro avg       0.70      0.68      0.68       154\n","weighted avg       0.71      0.72      0.71       154\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"6W6jiW3MQYB-"},"source":["Atividade 7:\n","\n","1. Implementar a validação da Random Forest através da classe *RandomizedSearchCV* do pacote *sklearn.model_selection*;\n","2. Imprimir os parâmetros do melhor classificador;\n","3. Imprimir os $E_{in}$ e $E_{out}$ e as métricas de aprendizado.\n","\n","Parâmetros:\n","\n","\n","*   *n_iter* : número aleatório de combinações dos parâmetros que serão validadas.\n","\n"]},{"cell_type":"code","metadata":{"id":"xZoyCf8AhF7E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636019949410,"user_tz":180,"elapsed":9892,"user":{"displayName":"Gilberto Farias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08659255523274913012"}},"outputId":"aae91b0d-d4f3-4b65-e44e-03c70af08631"},"source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","\n","rf = RandomForestClassifier()\n","\n","rf_random = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, n_iter = 25, cv = 5, verbose=2, n_jobs=-1, random_state=42)\n","\n","# Fit the random search model\n","rf_random.fit(x_train, y_train)\n","\n","print(rf_random.best_estimator_)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, rf_random.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, rf_random.predict(x_test))))\n","print(classification_report(y_test, rf_random.predict(x_test)))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"]},{"output_type":"stream","name":"stderr","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.9s\n","[Parallel(n_jobs=-1)]: Done 122 out of 125 | elapsed:    9.3s remaining:    0.2s\n","[Parallel(n_jobs=-1)]: Done 125 out of 125 | elapsed:    9.4s finished\n"]},{"output_type":"stream","name":"stdout","text":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=40, max_features=8,\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=30,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)\n","Ein: 0.0000\n","Eout: 0.2857\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.84      0.79        98\n","           1       0.64      0.50      0.56        56\n","\n","    accuracy                           0.71       154\n","   macro avg       0.69      0.67      0.67       154\n","weighted avg       0.71      0.71      0.71       154\n","\n"]}]}]}