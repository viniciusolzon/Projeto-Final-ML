{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prática2_Árvore de Decisão-Parâmetros_resolvido.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOgr+YHw/NwDVc5tfonZUkG"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sKPfuEnapDnU"},"source":["<font color=\"darkblue\"> Prática 02: Árvore de Decisão - parâmetros </font>"]},{"cell_type":"markdown","metadata":{"id":"nKa5whanpntS"},"source":["**Objetivos:**\n","\n","*   Efetuar um experimento de classificação com dados reais usando a classe $DecisionTreeClassifier$ do pacote $sklearn.tree$;\n","*   Plotar a árvore de decisão inferida em arquivo e na tela; \n","*   Analisar os principais parâmetros da classe $DecisionTreeClassifier$.\n","\n","\n","**Requisitos de execução:**\n","\n","\n","*   Upload do arquivo *diabetes.csv*"]},{"cell_type":"markdown","metadata":{"id":"OPCbV-Udr1Pz"},"source":["**Atividade 1:**\n","\n","1. Visitar a base de dados: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n","2. Carregar os dados do arquivo *diabetes.csv* utilizando o pandas.\n","\n","    "]},{"cell_type":"code","metadata":{"id":"ZROjmwlFocyd"},"source":["import pandas as pd \n","\n","diabete = pd.read_csv(\"diabetes.csv\", sep=',')\n","\n","# Pega o cabecalho do arquivo\n","print(diabete.head())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O73AMlZRtOTU"},"source":["**Atividade 2:**\n","\n","1. Extrair os valores do *DataFrame* pandas e dividir em dados de treino e de teste\n"]},{"cell_type":"code","metadata":{"id":"sU9ugDeOtaHd"},"source":["from sklearn.model_selection import train_test_split\n","\n","Features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',  'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n","X = diabete[Features].values\n","y = diabete.Outcome.values\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2698)\n","\n","print(\"Tamanho treino: \" + str(len(x_train)))\n","print(\"Tamanho teste: \" + str(len(x_test)))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGjfXNZ-tsor"},"source":["**Atividade 3:**\n","\n","1. Utilize a classe *DecisionTreeClassifier*, importada do pacote *sklearn.tree*, para inferir aprendizado dos dados de treinamento;\n","2. Compute as métricas de aprendizado sobre os dados de teste."]},{"cell_type":"code","metadata":{"id":"jvw7C1Odt3Jb"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","clf = DecisionTreeClassifier()\n","clf.fit(x_train, y_train)\n","\n","\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, clf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, clf.predict(x_test))))\n","print(classification_report(y_test, clf.predict(x_test)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0SH_p2JeTmEN"},"source":["**Atividade 4:**\n","\n","1. Liste os atributos dos dados com o seu valor de importância usado na divisão dos nós da árvore de decisão."]},{"cell_type":"code","metadata":{"id":"GbnZN9PUQQ0d"},"source":["from matplotlib import pyplot as plt\n","\n","for feature, importance in zip(Features, clf.feature_importances_):\n","    print(\"{}:{}\".format(feature, importance))\n","\n","plt.bar(Features, clf.feature_importances_)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7eMziL89QAyK"},"source":["**Atividade 5:**\n","\n","1. Plote a árvore de decisão criada pelo classificador usando a função *plot_tree*;\n","2. Salve a figura em arquivo."]},{"cell_type":"code","metadata":{"id":"uZXxRdSyQBLX"},"source":["from sklearn.tree import plot_tree\n","from matplotlib import pyplot as plt\n","\n","# feature labels\n","features_label = (diabete.drop('Outcome',axis=1)).columns\n","\n","# class label\n","class_label = ['0','1']\n","\n","plt.figure(figsize=(50,20))\n","plot_tree(\n","    clf, \n","    feature_names = features_label,\n","    class_names = class_label, \n","    filled=True, \n","    proportion = True,\n","    fontsize=6, \n","    rounded = True)\n","\n","plt.savefig('filename.png')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hqoDADDkSBff"},"source":["**Atividade 6:**\n","\n","1. Plote a árvore de decisão criada pelo classificador usando a função *export_graphviz*."]},{"cell_type":"code","metadata":{"id":"xZoyCf8AhF7E"},"source":["import pydot\n","import graphviz\n","from sklearn.tree import export_graphviz\n","\n","dot_data = export_graphviz( \n","         clf, \n","         out_file = None,\n","         feature_names = features_label,\n","         class_names = class_label,  \n","         filled = True, \n","         rounded = True,\n","         proportion = True,\n","         node_ids = True,\n","         rotate  =False,\n","         label = 'all',\n","         special_characters = True\n","        )  \n","graph = graphviz.Source(dot_data)  \n","graph"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fyr1aWvJQGbI"},"source":["**Atividade 7:**\n","\n","1. Criar uma interface iterativa para configurar os parâmetros da *DecisionTreeClassifier*\n","2. Analisar o resultado produzido pelos parâmtros em termos de $E_{in}$ e $E_{out}$ \n","\n","\n","\n","> Parâmetros:\n","\n","*   *criterion* : medida de qualidade da divisão dos nós. $[entropy, gain]$;\n","*   *splitter* : estratégia de divisão dos nós. $[best, random]$;\n","*   *max_depth* : máxima profundidade da árvore;\n","*   *min_samples_split* : número mínimo de amostras requeridas para dividir um nó;\n","*   *min_samples_leaf* : quantidade mínima de amostras para ser um nó folha. Um nó só divide se seus filhos tiverem esta quantidade garantida.\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"SGqo7qhUQHrY"},"source":["from ipywidgets import interactive\n","from IPython.display import SVG,display\n","from graphviz import Source\n","\n","def plot_tree(crit, split, depth, min_samples_split, min_samples_leaf=0.2):\n","    estimator = DecisionTreeClassifier(\n","           random_state = 0 \n","          ,criterion = crit\n","          ,splitter = split\n","          ,max_depth = depth\n","          ,min_samples_split=min_samples_split\n","          ,min_samples_leaf=min_samples_leaf\n","    )\n","    estimator.fit(x_train, y_train)\n","\n","    print('Ein: %0.4f' % (1 - accuracy_score(y_train, estimator.predict(x_train))))\n","    print('Eout: %0.4f' % (1 - accuracy_score(y_test, estimator.predict(x_test))))\n","\n","    print(classification_report(y_test, estimator.predict(x_test)))\n","    graph = Source(export_graphviz(estimator\n","      , out_file=None\n","      , feature_names=features_label\n","      , class_names=class_label\n","      , impurity=True\n","      , filled = True))\n","    \n","    display(SVG(graph.pipe(format='svg')))\n","    return estimator\n","\n","inter=interactive(plot_tree \n","   , crit = [\"gini\", \"entropy\"]\n","   , split = [\"best\", \"random\"]\n","   , depth=[1,2,3,4,5,10,20,30]\n","   , min_samples_split=(1,8)\n","   , min_samples_leaf=(1,20))\n","\n","display(inter)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GqZ2Ow9nSYmP"},"source":["**Atividade 8:**\n","\n","1. Implementar um código que exiba a sequência de regras seguidas pela árvore de decisão durante a classificação de um novo dado de entrada."]},{"cell_type":"code","metadata":{"id":"v-95ru6Ax7-z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636019715650,"user_tz":180,"elapsed":476,"user":{"displayName":"Gilberto Farias","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"08659255523274913012"}},"outputId":"b5e1cbe0-5e14-46ac-a3aa-be76511fca06"},"source":["\n","def extract_rules(sample_id, clf):\n","    x_sample = x_test[sample_id]\n","\n","    #Id das features analisadas em cada nó da árvore de decisão\n","    feature = clf.tree_.feature\n","\n","    #Limiar de decisão de cada nó da árvore\n","    threshold = clf.tree_.threshold\n","\n","    #Acessa o caminho de nós da árvore até a folha de predicao da amostra\n","    node_indices = clf.decision_path([x_sample]).indices \n","   \n","    #Último nó do caminho é a folha de predição\n","    leaf_id = node_indices[-1]\n","   \n","    print('\\nFeatures usadas para predizer a amostra %s' % (sample_id))\n","\n","    for f, v in zip(diabete.columns, x_sample):\n","        print('%s = %s'%(f,v))\n","    print('\\n')      \n","\n","    for node_id in node_indices:\n","        if leaf_id == node_id:\n","            break\n","\n","\n","        if (x_sample[feature[node_id]] <= threshold[node_id]):\n","            threshold_sign = \"<=\"\n","        else:\n","            threshold_sign = \">\"\n","\n","        print(\"id do nó de decisão %s : (atributo %s com valor = %s %s %s)\"\n","              % (node_id,\n","                 diabete.columns[feature[node_id]],\n","                 x_sample[feature[node_id]],\n","                 threshold_sign,\n","                 threshold[node_id]))\n","        \n","    pred = clf.predict([x_sample])\n","\n","    print(\"\\tClasse => %s\" %pred)\n","\n","\n","extract_rules(2, clf)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Features usadas para predizer a amostra 2\n","Pregnancies = 10.0\n","Glucose = 111.0\n","BloodPressure = 70.0\n","SkinThickness = 27.0\n","Insulin = 0.0\n","BMI = 27.5\n","DiabetesPedigreeFunction = 0.141\n","Age = 40.0\n","\n","\n","id do nó de decisão 0 : (atributo Glucose com valor = 111.0 <= 127.5)\n","id do nó de decisão 1 : (atributo BMI com valor = 27.5 > 27.0)\n","id do nó de decisão 11 : (atributo Age com valor = 40.0 > 25.5)\n","id do nó de decisão 43 : (atributo DiabetesPedigreeFunction com valor = 0.141 <= 1.1049999594688416)\n","id do nó de decisão 44 : (atributo BMI com valor = 27.5 <= 46.75)\n","id do nó de decisão 45 : (atributo Glucose com valor = 111.0 <= 123.5)\n","id do nó de decisão 46 : (atributo Insulin com valor = 0.0 <= 142.5)\n","id do nó de decisão 47 : (atributo BloodPressure com valor = 70.0 > 67.0)\n","id do nó de decisão 63 : (atributo Glucose com valor = 111.0 > 28.5)\n","id do nó de decisão 65 : (atributo DiabetesPedigreeFunction com valor = 0.141 <= 0.8059999942779541)\n","id do nó de decisão 66 : (atributo Pregnancies com valor = 10.0 <= 11.5)\n","id do nó de decisão 67 : (atributo BloodPressure com valor = 70.0 <= 98.0)\n","id do nó de decisão 68 : (atributo Age com valor = 40.0 <= 51.0)\n","id do nó de decisão 69 : (atributo BMI com valor = 27.5 <= 31.0)\n","id do nó de decisão 70 : (atributo SkinThickness com valor = 27.0 <= 33.5)\n","id do nó de decisão 71 : (atributo BMI com valor = 27.5 <= 30.449999809265137)\n","\tClasse => [0]\n"]}]}]}