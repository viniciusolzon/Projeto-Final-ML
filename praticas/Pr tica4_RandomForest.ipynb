{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Prática4_RandomForest.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOSsDqbLf2EzFfSHtOvjJmg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sKPfuEnapDnU"},"source":["# <font color=\"darkblue\"> Prática 04: Random Forest </font>"]},{"cell_type":"markdown","metadata":{"id":"nKa5whanpntS"},"source":["**Objetivos:**\n","\n","\n","*   Comparar os resultados da Árvore de Decisão induzida por dados com o algoritmo de *Random Forest*;\n","*   Implementar o *tunning* do algoritmo de *Random Forest*.  \n","\n","**Requisitos de execução:**\n","\n","\n","*   Upload do arquivo *diabetes.csv*"]},{"cell_type":"markdown","metadata":{"id":"OPCbV-Udr1Pz"},"source":["**Atividade 1:**\n","\n","1. Visitar a base de dados: https://www.kaggle.com/uciml/pima-indians-diabetes-database\n","2. Carregar os dados do arquivo *diabetes.csv* utilizando o pandas.\n","\n","    "]},{"cell_type":"code","metadata":{"id":"ZROjmwlFocyd","colab":{"base_uri":"https://localhost:8080/","height":163},"executionInfo":{"status":"ok","timestamp":1602872539299,"user_tz":180,"elapsed":1608,"user":{"displayName":"Gilberto Farias","photoUrl":"","userId":"08659255523274913012"}},"outputId":"6561472d-fad7-4657-fe26-7b7c51d63476"},"source":["import pandas as pd \n","\n","diabete = pd.read_csv(\"diabetes.csv\", sep=',')\n","\n","# Pega o cabecalho do arquivo\n","print(diabete.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n","0            6      148             72  ...                     0.627   50        1\n","1            1       85             66  ...                     0.351   31        0\n","2            8      183             64  ...                     0.672   32        1\n","3            1       89             66  ...                     0.167   21        0\n","4            0      137             40  ...                     2.288   33        1\n","\n","[5 rows x 9 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O73AMlZRtOTU"},"source":["**Atividade 2:**\n","\n","1. Extrair os valores do *DataFrame* pandas e dividir en dados de treino e teste.\n"]},{"cell_type":"code","metadata":{"id":"sU9ugDeOtaHd","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1602872542012,"user_tz":180,"elapsed":739,"user":{"displayName":"Gilberto Farias","photoUrl":"","userId":"08659255523274913012"}},"outputId":"7b0ac387-6ff8-4f33-d8d2-b78e494f7a34"},"source":["from sklearn.model_selection import train_test_split\n","\n","Features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',  'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n","X = diabete[Features].values\n","y = diabete.Outcome.values\n","\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2698)\n","\n","print(\"Tamanho treino: \" + str(len(x_train)))\n","print(\"Tamanho teste: \" + str(len(x_test)))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tamanho treino: 614\n","Tamanho teste: 154\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gGjfXNZ-tsor"},"source":["**Atividade 3:**\n","\n","1. Utilize a classe *DecisionTreeClassifier*, importada do pacote *sklearn.tree*, para inferir aprendizado dos dados de treinamento;\n","2. Compute as métricas de aprendizado sobre os dados de teste."]},{"cell_type":"code","metadata":{"id":"jvw7C1Odt3Jb","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"ok","timestamp":1602872555297,"user_tz":180,"elapsed":819,"user":{"displayName":"Gilberto Farias","photoUrl":"","userId":"08659255523274913012"}},"outputId":"e707c098-a7e5-45d8-fe62-8792fff65000"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","\n","clf = DecisionTreeClassifier()\n","clf.fit(x_train, y_train)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, clf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, clf.predict(x_test))))\n","print(classification_report(y_test, clf.predict(x_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Ein: 0.0000\n","Eout: 0.3052\n","              precision    recall  f1-score   support\n","\n","           0       0.74      0.80      0.77        98\n","           1       0.59      0.52      0.55        56\n","\n","    accuracy                           0.69       154\n","   macro avg       0.67      0.66      0.66       154\n","weighted avg       0.69      0.69      0.69       154\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0SH_p2JeTmEN"},"source":["**Atividade 4:**\n","\n","\n","1. Utilize a classe *RandomForestClassifier*, importada do pacote *sklearn.ensemble*, para inferir aprendizado dos dados de treinamento;\n","2. Compute as métricas de aprendizado sobre os dados de teste e compare com os resultados da atividade anterior.\n","\n","Parâmetros:\n","\n","\n","*   *n_estimators* : número de árvore aleatórias inferidas\n","*   *max_depth* : profundidade máxima da árvore\n","\n"]},{"cell_type":"code","metadata":{"id":"GbnZN9PUQQ0d","colab":{"base_uri":"https://localhost:8080/","height":217},"executionInfo":{"status":"ok","timestamp":1602872557860,"user_tz":180,"elapsed":717,"user":{"displayName":"Gilberto Farias","photoUrl":"","userId":"08659255523274913012"}},"outputId":"7999714b-ed12-448f-d9b9-fe3fef621f1d"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","rf = RandomForestClassifier(n_estimators = 100, max_depth = 30, random_state=42)\n","\n","rf.fit(x_train, y_train)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, rf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, rf.predict(x_test))))\n","print(classification_report(y_test, rf.predict(x_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Ein: 0.0000\n","Eout: 0.2727\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.87      0.80        98\n","           1       0.68      0.48      0.56        56\n","\n","    accuracy                           0.73       154\n","   macro avg       0.71      0.67      0.68       154\n","weighted avg       0.72      0.73      0.71       154\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7eMziL89QAyK"},"source":["**Atividade 5:**\n","\n","1. Implemente os valores dos hiperparâmetros que serão combinados durantea a fase de validação\n","\n","Parâmetros:\n","\n","*   *max_features* : número de características a serem consideradas em cada divisão da árvore\n","\n"]},{"cell_type":"code","metadata":{"id":"uZXxRdSyQBLX","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1602872588431,"user_tz":180,"elapsed":740,"user":{"displayName":"Gilberto Farias","photoUrl":"","userId":"08659255523274913012"}},"outputId":"a9039f5e-c241-4dea-dc2f-d468cb4ddd5b"},"source":["import numpy as np\n","from pprint import pprint\n","\n","n_estimators = [int(x) for x in np.linspace(start=20, stop = 70, num=6)]\n","max_features = ['sqrt', 'log2', 8]\n","max_depth = [int(x) for x in np.linspace(start=10, stop = 40, num=4)]\n","max_depth.append(None)\n","\n","param_grid = {\n","    'n_estimators' : n_estimators,\n","    'max_features' : max_features,\n","    'max_depth' : max_depth\n","}\n","\n","pprint(param_grid)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["{'max_depth': [10, 20, 30, 40, None],\n"," 'max_features': ['sqrt', 'log2', 8],\n"," 'n_estimators': [20, 30, 40, 50, 60, 70]}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"voPhxvG5Yd19"},"source":["Atividade 6:\n","\n","1. Implementar a validação da Random Forest através da classe *GridSearchCV* do pacote *sklearn.model_selection*;\n","2. Imprimir os parâmetros do melhor classificador;\n","3. Imprimir os $E_{in}$ e $E_{out}$  e as métricas de aprendizado.\n","\n","Parâmetros:\n","\n","\n","*   *estimator* : instância do classificador cujos hiperparâmetros serão analisados;\n","*   *cv* : número de divisões do conjunto de treinamento para ser usado na técnica de validação cruzada (10 é um bom valor observado na prática);\n","*   *param_grid* : conjunto de parâmetros a serem combinados durante a fase de validação.\n","\n"]},{"cell_type":"code","metadata":{"id":"wj5q5XfBe80u","colab":{"base_uri":"https://localhost:8080/","height":454},"executionInfo":{"status":"ok","timestamp":1602705794527,"user_tz":180,"elapsed":35111,"user":{"displayName":"Gilberto Farias","photoUrl":"","userId":"08659255523274913012"}},"outputId":"89d29b7c-359d-4de0-c4ea-7d7003dd9304"},"source":["from sklearn.model_selection import GridSearchCV\n","\n","rf = RandomForestClassifier()\n","\n","cv_rf = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 5, verbose=2, n_jobs=-1)\n","\n","cv_rf.fit(x_train, y_train)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, cv_rf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, cv_rf.predict(x_test))))\n","print(classification_report(y_test, cv_rf.predict(x_test)))\n","\n","print(cv_rf.best_estimator_)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed:    4.6s\n","[Parallel(n_jobs=-1)]: Done 312 tasks      | elapsed:   22.9s\n"],"name":"stderr"},{"output_type":"stream","text":["Ein: 0.0000\n","Eout: 0.2792\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.85      0.79        98\n","           1       0.65      0.50      0.57        56\n","\n","    accuracy                           0.72       154\n","   macro avg       0.70      0.67      0.68       154\n","weighted avg       0.71      0.72      0.71       154\n","\n","RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=40, max_features='sqrt',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=70,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:   33.9s finished\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"6W6jiW3MQYB-"},"source":["**Atividade 7:**\n","\n","1. Implementar a validação da Random Forest através da classe *RandomizedSearchCV* do pacote *sklearn.model_selection*;\n","2. Imprimir os parâmetros do melhor classificador;\n","3. Imprimir os $E_{in}$ e $E_{out}$ e as métricas de aprendizado.\n","\n","Parâmetros:\n","\n","\n","*   *n_iter* : número aleatório de combinações dos parâmetros que serão validadas.\n","\n"]},{"cell_type":"code","metadata":{"id":"xZoyCf8AhF7E","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1602872651783,"user_tz":180,"elapsed":35796,"user":{"displayName":"Gilberto Farias","photoUrl":"","userId":"08659255523274913012"}},"outputId":"d69172f9-fd4c-4347-d410-7f571bc959cc"},"source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","rf = RandomForestClassifier()\n","\n","cv_rf = RandomizedSearchCV(estimator = rf, param_distributions = param_grid, n_iter = 225, cv = 5, verbose=2, n_jobs=-1)\n","\n","cv_rf.fit(x_train, y_train)\n","\n","print(cv_rf.best_estimator_)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, cv_rf.predict(x_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, cv_rf.predict(x_test))))\n","print(classification_report(y_test, cv_rf.predict(x_test)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 90 is smaller than n_iter=225. Running 90 iterations. For exhaustive searches, use GridSearchCV.\n","  % (grid_size, self.n_iter, grid_size), UserWarning)\n","[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    3.3s\n","[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:   12.3s\n"],"name":"stderr"},{"output_type":"stream","text":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=10, max_features='log2',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=20,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)\n","Ein: 0.0195\n","Eout: 0.3052\n","              precision    recall  f1-score   support\n","\n","           0       0.71      0.87      0.78        98\n","           1       0.63      0.39      0.48        56\n","\n","    accuracy                           0.69       154\n","   macro avg       0.67      0.63      0.63       154\n","weighted avg       0.68      0.69      0.67       154\n","\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Done 450 out of 450 | elapsed:   35.0s finished\n"],"name":"stderr"}]}]}