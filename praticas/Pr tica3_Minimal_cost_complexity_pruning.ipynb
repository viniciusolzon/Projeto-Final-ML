{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"name":"Prática3_Minimal_cost_complexity_pruning.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"froZjtS1UAlZ"},"source":["# <font color=\"darkblue\"> Prática 03: Minimal Cost-Complexity Prunning </font>"]},{"cell_type":"markdown","metadata":{"id":"n4JH_RJlUAAR"},"source":["**Objetivos:**\n","\n","\n","*   Compreender o funcionamento do algoritmo Minimal cost-Complexity Prunning para a realização de podas em uma árvore de decisão;\n","\n","*   Regularizar o parâmetro de complexidade $\\alpha$ através de validação.  "]},{"cell_type":"markdown","metadata":{"id":"I5ZPDHENdBUm"},"source":["**Atividade 1:**\n","\n"," \n","\n","1.   Carregue a base de dados Wisconsin sobre classificação de câncer de mama. Esta base está disponível no pacote sklearn.datasets;\n","2.   Divide a instância em treino (80%) e teste(20%)."]},{"cell_type":"code","metadata":{"id":"8iKlvH3Ka3nG"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.datasets import load_breast_cancer\n","\n","X, y = load_breast_cancer(return_X_y=True)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n","\n","print(\"N: \" + str(len(X)))\n","print(\"d: \" + str(len(X[0])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jmuVFKU7exOA"},"source":["**Atividade 2:**\n","\n","1. Utilize a classe *DecisionTreeClassifier*, importada do pacote *sklearn.tree*, para inferir aprendizado dos dados de treinamento;\n","2. Compute as métricas de aprendizado sobre os dados de teste usando as funções *classification_report*, *accuracy_score* do pacote *sklearn.metrics*."]},{"cell_type":"code","metadata":{"id":"ALTylrz7LQvU"},"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import classification_report, accuracy_score\n","from sklearn.tree import plot_tree\n","from matplotlib import pyplot as plt\n","\n","\n","clf = DecisionTreeClassifier(random_state=0)\n","clf.fit(X_train, y_train)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, clf.predict(X_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, clf.predict(X_test))))\n","print(classification_report(y_test, clf.predict(X_test)))\n","\n","#Desenho da árvore\n","plt.figure(figsize=(50,20))\n","plot_tree(\n","    clf,\n","    filled=True, \n","    proportion = True,\n","    fontsize=12, \n","    rounded = True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yhry0JLkiz2A"},"source":["**Minimal Cost-Complexity Pruning**\n","\n","É um algoritmo usado para podar nós da árvore evitando o surgimento de *overfitting*. Este algoritmo é parametrizado por $\\alpha\\geq0$ conhecido como parâmetro de complexidade da árvore. Este parâmetro é usado para definir o *cost-complexity* $R_{\\alpha}(T)$ de uma dada árvore $T$, sendo a fórmula: \n","\n","> $R_{\\alpha}(T)=R(T) + \\alpha\\cdot| leafes(T) |,$\n","\n","onde:\n","\n","*   $R(T) : $ são erros de classificação da árvore $T$ nos dados de treino;\n","*   $| leafes(T) | : $ número de folhas de decisão da árvore $T$.\n","\n","O algoritmo *Minimal Cost-Complexity Pruning* procura a sub árvore que minimiza o $R_{\\alpha}(T)$.\n","\n","Alternativamente, o *sciki-learn* utiliza a impureza dos nós folhas, dados mal classificados que caíram naquele nó, para medir o $R(T)$. A medida *cost-complexity* de um único nó é $R_{\\alpha}(t) = R(t) + \\alpha$. A ramificação $T_t$ é definida para ser uma árvore onde o nó $t$ é raiz. Em geral a impureza de um nó é maior do que a soma das impurezas de seus nós terminais, $R(T_t) < R(t)$. Entretanto, as medidas de *cost-complexity* de um nó $t$ e sua ramificação podem ser iguais dependendo do valor de $\\alpha$. Define-se o $\\alpha$ efetivo de um nó $t$ o valor obtido quando $R_{\\alpha}(T_t) = R_{\\alpha}(t)$, sendo sua fórmula $\\alpha_{eff}(t) = \\frac{R(t)-R(T_t)}{|T|-1} $. Um nó não terminal com o menor valor de $\\alpha_{eff}$ é um elo mais fraco e deve ser podado. Este processo acaba quando o menor valor de $\\alpha_{eff}$ é maior que o valor do parâmetro *ccp_alpha*.  \n","\n","\n","---\n","\n","\n","**Atividade 3:**\n","\n","1. Quebrar os dados de treino em : dados de treino (80%), dados de validação (20%);\n","2. Computar o Cost-Complexity Pruning da instância de treino através da função *cost_complexity_pruning_path* do objeto *DecisionTreeClassifier*;\n","3. Plotar um gráfico com a relação entre o valor de impureza dos nós folha e o valor efetivo de alpha para a realização do prunning."]},{"cell_type":"code","metadata":{"id":"odF4VN2Lwwv8"},"source":["#Divide os dados em treino e validação \n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=0)\n","\n","#Recupera os valores efetivos de alpha para a elaboração da fase de prunning\n","path = clf.cost_complexity_pruning_path(X_train, y_train)\n","ccp_alphas, impurities = path.ccp_alphas, path.impurities\n","\n","#Plota a relação entre os valores de alpha e impureza das folhas\n","fig, ax = plt.subplots()\n","ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n","ax.set_xlabel(\"alpha efetivo\")\n","ax.set_ylabel(\"total impureza das folhas\")\n","ax.set_title(\"Impureza vs alpha efetivo para os dados de treino\")\n","fig.show()\n","\n","print(ccp_alphas)\n","print(impurities)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"10sVdKGawwv9"},"source":["**Atividade 4:**\n","\n","1. Construir uma lista de DecisionTreeClassifier com os valores efetivos de $\\alpha$ configurados para a realização do processo de validação do parâmetro *ccp_alpha* utilizando os dados de treinamento;\n","2. Plotar gráficos com as relações entre o valor do $\\alpha$ e o número de nós e o valor de $\\alpha$ e a profundidade das árvores.\n","\n"]},{"cell_type":"code","metadata":{"id":"qo46TcZYwwv-"},"source":["clfs = []\n","for ccp_alpha in ccp_alphas:\n","    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n","    clf.fit(X_train, y_train)\n","    clfs.append(clf)\n","\n","#Descarta o último por ser trivial (apenas o nó raiz)\n","clfs = clfs[:-1]\n","ccp_alphas = ccp_alphas[:-1]\n","\n","node_counts = [clf.tree_.node_count for clf in clfs]\n","depth = [clf.tree_.max_depth for clf in clfs]\n","fig, ax = plt.subplots(2, 1)\n","ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n","ax[0].set_xlabel(\"alpha\")\n","ax[0].set_ylabel(\"número de nós\")\n","ax[0].set_title(\"Número de nós vs alpha\")\n","ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n","ax[1].set_xlabel(\"alpha\")\n","ax[1].set_ylabel(\"profundidade da árvore\")\n","ax[1].set_title(\"Profundidade vs alpha\")\n","fig.tight_layout()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TF1F9dWiwwwA"},"source":["**Atividade 5:**\n","\n","1. Utilizar a instância de treinamento e validação para computar as acurácias de de cada conjunto de dados\n","2. Plotar a relação entre os valores de acurária e os valores de $\\alpha$ validados.\n","\n"]},{"cell_type":"code","metadata":{"id":"Bssx16WdwwwA"},"source":["import matplotlib.pyplot as plt\n","\n","train_scores = [clf.score(X_train, y_train) for clf in clfs]\n","val_scores = [clf.score(X_val, y_val) for clf in clfs]\n","\n","fig, ax = plt.subplots()\n","ax.set_xlabel(\"alpha\")\n","ax.set_ylabel(\"accuracy\")\n","ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n","ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n","ax.plot(ccp_alphas, val_scores, marker=\"o\", label=\"validation\", drawstyle=\"steps-post\")\n","ax.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RzEEE3RMyjkp"},"source":["**Atividade 6:**\n","\n","1. Construir o classificador *DecisionTreeClassifier* com o valor do parâmetro $ccp\\_alpha$ que obteve o melhor resultado de acurácia na instância de validação; \n","2. Computar o valor de acurácia dos dados de teste e comparar com o classificador da Atividade 2."]},{"cell_type":"code","metadata":{"id":"L3_v6rT-OQN0"},"source":["clf = DecisionTreeClassifier(random_state=0, ccp_alpha=0.01943252)\n","clf.fit(X_train, y_train)\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, clf.predict(X_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, clf.predict(X_test))))\n","print(classification_report(y_test, clf.predict(X_test)))\n","\n","#Desenho da árvore\n","plt.figure(figsize=(50,20))\n","plot_tree(\n","    clf,\n","    filled=True, \n","    proportion = True,\n","    fontsize=36, \n","    rounded = True)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wvJhOdHmzFgi"},"source":["**Atividade 7:**\n","\n","1. Repetir o processo de validação do parâmetro *ccp_alpha* usando a classe *GridSearchCV* do pacote sklearn.model_selection; \n","2. Computar o valor de acurácia dos dados de teste e comparar com o classificador das Atividades 2 e 6.\n","\n","Parâmetros:\n","\n","\n","*   *estimator* : instância do classificador cujos hiperparâmetros serão analisados;\n","*   *cv* : número de divisões do conjunto de treinamento para ser usado na técnica de validação cruzada (10 é um bom valor observado na prática);\n","*   *param_grid* : conjunto de parâmetros a serem combinados durante a fase de validação."]},{"cell_type":"code","metadata":{"id":"6iZhDR_qPCtu"},"source":["from sklearn.model_selection import GridSearchCV\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n","\n","clf = DecisionTreeClassifier(random_state=0)\n","path = clf.cost_complexity_pruning_path(X_train, y_train)\n","\n","param_grid = {'ccp_alpha': path.ccp_alphas}\n","\n","CV_clf = GridSearchCV(estimator=clf, param_grid=param_grid, cv = 7, verbose=2, n_jobs=-1)\n","CV_clf.fit(X_train, y_train)\n","\n","\n","print('Ein: %0.4f' % (1 - accuracy_score(y_train, CV_clf.predict(X_train))))\n","print('Eout: %0.4f' % (1 - accuracy_score(y_test, CV_clf.predict(X_test))))\n","print(classification_report(y_test, CV_clf.predict(X_test)))"],"execution_count":null,"outputs":[]}]}